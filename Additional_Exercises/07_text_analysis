{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07_text_analysis","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWkLBxjsNoYMKpzrafNprL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Working with text\n","\n","Usually, we face a collection of documents with a certain number of unique words (terms), the sum of all words is the lexicon and the document collection is called a corpus. Each document consists of a sequence of words which are called tokens in this context. A term is the unique word in the overall corpus. A token is a word in a document which may appear more than once in the document and among all documents. Let us create a small corpus. Each sentence represents a document."],"metadata":{"id":"uI91XSHuBbI2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"mdisgHFoBUJE","executionInfo":{"status":"ok","timestamp":1642158614798,"user_tz":-60,"elapsed":7,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}}},"outputs":[],"source":["my_texts = [\n","    'Machine learning is so so interesting!',\n","    'After having 5 coffees, I am awake.',\n","    'Waking up and studying is not funny.',\n","    'The coffee machine is broken, what am I supposed to do?',\n","    'Coffee machines are interesting to study.'\n","]\n","Sample_Text = \"After having 5 coffees, I am awake\""]},{"cell_type":"markdown","source":["Before we do anything, text must be preprocesses. This can be tricky for certain documents, but, for the moment we will use an easy self-made implementation of some existing functions which will do a good job for the majority of documents. Typical steps of preprocessing include exclusion of punctuation, the transformation to lower case letters, the removal of numbers and sometimes further steps such as the removal of stopwords and stemming. "],"metadata":{"id":"q1T3D8w2Bajn"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import string\n","from gensim.parsing.preprocessing import STOPWORDS\n","import nltk\n","\n","# import a stemmer for english words\n","snowStem = nltk.stem.SnowballStemmer('english')"],"metadata":{"id":"7lAN-uRXCt3I","executionInfo":{"status":"ok","timestamp":1642158617085,"user_tz":-60,"elapsed":2292,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["The following languages are supported: Arabic, Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish and Swedish.\n","\n","The algorithm for English is documented here:\n","\n","Porter, M. “An algorithm for suffix stripping.” Program 14.3 (1980): 130-137.\n","\n","The algorithms have been developed by Martin Porter. These stemmers are called Snowball, because Porter created a programming language with this name for creating new stemming algorithms."],"metadata":{"id":"25btmQpfDn4a"}},{"cell_type":"code","source":["# remove numbers \n","Sample_Text = re.sub(r'\\d+', '', Sample_Text)\n","print (Sample_Text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKHsXHQWBtkg","executionInfo":{"status":"ok","timestamp":1642158617099,"user_tz":-60,"elapsed":36,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"2a61488e-26d7-4583-9f89-d7e89e2f916a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["After having  coffees, I am awake\n"]}]},{"cell_type":"markdown","source":["the re module provides regular expression matching operations similar to those found in Perl. Both patterns and strings to be searched can be Unicode strings (str) as well as 8-bit strings (bytes). However, Unicode strings and 8-bit strings cannot be mixed: that is, you cannot match a Unicode string with a byte pattern or vice-versa; similarly, when asking for a substitution, the replacement string must be of the same type as both the pattern and the search string.\n","\n","re.sub(pattern, repl, string, count=0, flags=0)\n","Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function;\n","\n","\\d\n","For Unicode (str) patterns:\n","Matches any Unicode decimal digit (that is, any character in Unicode character category [Nd]). This includes [0-9], and also many other digit characters. If the ASCII flag is used only [0-9] is matched.\n","\n"],"metadata":{"id":"OgKkln3aEMs6"}},{"cell_type":"code","source":["# remove punctuation\n","Sample_Text = Sample_Text.translate(str.maketrans('','', string.punctuation))\n","print(Sample_Text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZonC5-pFvH3","executionInfo":{"status":"ok","timestamp":1642158617099,"user_tz":-60,"elapsed":28,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"bdacd1c9-93e7-41e7-a057-97cccde67f17"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["After having  coffees I am awake\n"]}]},{"cell_type":"markdown","source":["In order to remove the punctuation we are using the string.translate method. This method returns a string where some specified characters are replaced with the character described in a dictionary, or in a mapping table.\n","\n","As it is described we need to generate a mapping table first that is passed to the translate method. To do so we use the str.maketrans function. \n","\n","In simple terms, the maketrans() method is a static method that creates a one to one mapping of a character to its translation/replacement.\n","\n","It creates a Unicode representation of each character for translation.\n","\n","The syntax of maketrans() method is:\n","\n","string.maketrans(x, y, z)\n","\n","String maketrans() Parameters:\n","\n","x - If only one argument is supplied, it must be a dictionary.\n","The dictionary should contain a 1-to-1 mapping from a single character string to its translation OR a Unicode number (97 for 'a') to its translation.\n","\n","y - If two arguments are passed, it must be two strings with equal length. Each character in the first string is a replacement to its corresponding index in the second string.\n","\n","z - If three arguments are passed, each character in the third argument is mapped to None.\n","\n","\n","string.punctuation is what we need here and it is\n","\n","String of ASCII characters which are considered punctuation characters in the C locale: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~."],"metadata":{"id":"4rICSZjLGo3L"}},{"cell_type":"code","source":["# remove leading and ending white spaces\n","Sample_Text = Sample_Text.strip()\n","print(Sample_Text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GB11cMMvIv37","executionInfo":{"status":"ok","timestamp":1642158617100,"user_tz":-60,"elapsed":27,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"1b5fc248-628c-457e-debc-271a62a9fc63"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["After having  coffees I am awake\n"]}]},{"cell_type":"markdown","source":["The strip() method returns a copy of the string in which all chars have been stripped from the beginning and the end of the string (default whitespace characters)."],"metadata":{"id":"gdme47bKIwJa"}},{"cell_type":"code","source":["# stemming\n","Sample_Text = snowStem.stem(Sample_Text)\n","print(Sample_Text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FnX_GidJJLu","executionInfo":{"status":"ok","timestamp":1642158617100,"user_tz":-60,"elapsed":26,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"e6b5c3f7-1d7a-4d75-9d35-424ca2407c0e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["after having  coffees i am awak\n"]}]},{"cell_type":"code","source":["# remove stop words\n","Sample_Text = ' '.join([w for w in Sample_Text.split() if not(w in STOPWORDS)])\n","print(Sample_Text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-1GYcIIJal6","executionInfo":{"status":"ok","timestamp":1642158617100,"user_tz":-60,"elapsed":24,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"525913c0-837e-4fab-d9a1-7b12c4125792"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["having coffees awak\n"]}]},{"cell_type":"markdown","source":["One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data), are referred to as stop words. \n","\n","Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query. \n","We would not want these words to take up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to stop words.\n","\n","There are obviously several ways to remove stop words, we here are using the join function where we join every word to an empty string if it is not part of the stopwords variable."],"metadata":{"id":"rTO6wp6dJwSk"}},{"cell_type":"code","source":["Sample_Text.lower()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"-yJkzWJaKQip","executionInfo":{"status":"ok","timestamp":1642158617101,"user_tz":-60,"elapsed":24,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"d26d2557-2809-435d-9742-ea9840782bb8"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'having coffees awak'"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["In the last step we need to transform all the words to lower case. for this we use the .lower function.\n"," \n",".lower() is a built-in Python method primarily used for string handling. The .lower() method takes no arguments and returns the lowercased strings from the given string by converting each uppercase character to lowercase. If there are no uppercase characters in the given string, it returns the original string."],"metadata":{"id":"8stEtd9kKcDW"}},{"cell_type":"markdown","source":["Now that we did this step by step for an example text lets do it in a quick way for the whole corpus. After preprocessing, the above corpus looks as show below:\n"],"metadata":{"id":"9FiT-W8SKwSf"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"txZ3WcfxJJh1"}},{"cell_type":"code","source":["def my_preprocessor(text_to_clean, remove_stopwords = True, stemming = False):\n","    # remove numbers \n","    text_to_clean = re.sub(r'\\d+', '', text_to_clean)\n","    # remove punctuation\n","    text_to_clean = text_to_clean.translate(str.maketrans('','', string.punctuation))\n","    # remove leading and ending white spaces\n","    text_to_clean = text_to_clean.strip()\n","    #transform text to lower case\n","    text_to_clean = text_to_clean.lower()\n","\n","    if stemming:\n","      # stemming\n","      text_to_clean = snowStem.stem(text_to_clean)\n","    \n","    if remove_stopwords:\n","        # remove stop words\n","        text_to_clean = ' '.join([w for w in text_to_clean.split() if not(w in STOPWORDS)])\n","    \n","    return text_to_clean\n","\n","for text in my_texts:\n","  print(my_preprocessor(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RbO5_TVFnES","executionInfo":{"status":"ok","timestamp":1642158617101,"user_tz":-60,"elapsed":21,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"48a2f4a6-f246-4e64-8db2-455b60c6429d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["machine learning interesting\n","having coffees awake\n","waking studying funny\n","coffee machine broken supposed\n","coffee machines interesting study\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"-DBCYaY8KtxW"}},{"cell_type":"markdown","source":["We do not necessarily need to use our own function, as many methods come with their own preprocessing routines. For instance, let us take a look at the CountVectorizer which can generate a bag-of-word representation of our corpus. The output shows us how each of the documents is now represented by a numerical vector which could be used by a quantitative method. "],"metadata":{"id":"QLJfKKY5L3bh"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","count_vec = CountVectorizer()\n","\n","bow = count_vec.fit_transform(my_texts)\n","pd.DataFrame(data = bow.toarray(), columns = count_vec.get_feature_names())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"_O6uWDLuL4K6","executionInfo":{"status":"ok","timestamp":1642158617858,"user_tz":-60,"elapsed":776,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"42cea18d-dee2-4a75-8e17-b149b143b233"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-154541f3-7eaf-444e-aaa4-8f619de096a1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>after</th>\n","      <th>am</th>\n","      <th>and</th>\n","      <th>are</th>\n","      <th>awake</th>\n","      <th>broken</th>\n","      <th>coffee</th>\n","      <th>coffees</th>\n","      <th>do</th>\n","      <th>funny</th>\n","      <th>having</th>\n","      <th>interesting</th>\n","      <th>is</th>\n","      <th>learning</th>\n","      <th>machine</th>\n","      <th>machines</th>\n","      <th>not</th>\n","      <th>so</th>\n","      <th>study</th>\n","      <th>studying</th>\n","      <th>supposed</th>\n","      <th>the</th>\n","      <th>to</th>\n","      <th>up</th>\n","      <th>waking</th>\n","      <th>what</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-154541f3-7eaf-444e-aaa4-8f619de096a1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-154541f3-7eaf-444e-aaa4-8f619de096a1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-154541f3-7eaf-444e-aaa4-8f619de096a1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   after  am  and  are  awake  broken  ...  supposed  the  to  up  waking  what\n","0      0   0    0    0      0       0  ...         0    0   0   0       0     0\n","1      1   1    0    0      1       0  ...         0    0   0   0       0     0\n","2      0   0    1    0      0       0  ...         0    0   0   1       1     0\n","3      0   1    0    0      0       1  ...         1    1   1   0       0     1\n","4      0   0    0    1      0       0  ...         0    0   1   0       0     0\n","\n","[5 rows x 26 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["we are using the sklearn countvectorizer.\n","the syntax for this method looks like this\n","\n","sklearn.feature_extraction.text.CountVectorizer(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n","\n","As we can see this method has methods like, stop_words or lowercase, which we do not need because we already preprocessed our data.\n","\n","This method converts a collection of text documents to a matrix of token counts.\n","\n","This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix. Therefor in order to see the contents of our bag of words we need to generate a Dataframe. To do so we need to first transform the sparse representation into an array and then pass the array via pandas into a dataframe. The name of the columns are the feature names or in other words all the words that were included in our corpus after preprocessing.\n","\n","If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."],"metadata":{"id":"lNNj-8mgL_Vf"}},{"cell_type":"markdown","source":["Sometimes, the relative occurence per document is more meaningful than the absolute count of certain terms. This is, where the usage of term-frequency inverse-document-frequency can be helpful."],"metadata":{"id":"GfluNn4ZNhVi"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tfidf_vec = TfidfVectorizer()\n","\n","tfidf = tfidf_vec.fit_transform(my_texts)\n","pd.DataFrame(data = tfidf.toarray(), columns = tfidf_vec.get_feature_names())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"ZqfogP-eNjjB","executionInfo":{"status":"ok","timestamp":1642158617859,"user_tz":-60,"elapsed":17,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"49aa0613-cdbd-4f77-8067-413379c5a7ea"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-310dca19-a2a5-478e-8af8-010343065a48\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>after</th>\n","      <th>am</th>\n","      <th>and</th>\n","      <th>are</th>\n","      <th>awake</th>\n","      <th>broken</th>\n","      <th>coffee</th>\n","      <th>coffees</th>\n","      <th>do</th>\n","      <th>funny</th>\n","      <th>having</th>\n","      <th>interesting</th>\n","      <th>is</th>\n","      <th>learning</th>\n","      <th>machine</th>\n","      <th>machines</th>\n","      <th>not</th>\n","      <th>so</th>\n","      <th>study</th>\n","      <th>studying</th>\n","      <th>supposed</th>\n","      <th>the</th>\n","      <th>to</th>\n","      <th>up</th>\n","      <th>waking</th>\n","      <th>what</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.310527</td>\n","      <td>0.257766</td>\n","      <td>0.38489</td>\n","      <td>0.310527</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.769781</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.463693</td>\n","      <td>0.374105</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.463693</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.463693</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.463693</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.393795</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.393795</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.263729</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.393795</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.393795</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.393795</td>\n","      <td>0.393795</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.284319</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.352406</td>\n","      <td>0.284319</td>\n","      <td>0.000000</td>\n","      <td>0.352406</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.236010</td>\n","      <td>0.00000</td>\n","      <td>0.284319</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.352406</td>\n","      <td>0.352406</td>\n","      <td>0.284319</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.352406</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.449342</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.362526</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.362526</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.449342</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.449342</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.362526</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-310dca19-a2a5-478e-8af8-010343065a48')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-310dca19-a2a5-478e-8af8-010343065a48 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-310dca19-a2a5-478e-8af8-010343065a48');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      after        am       and  ...        up    waking      what\n","0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","1  0.463693  0.374105  0.000000  ...  0.000000  0.000000  0.000000\n","2  0.000000  0.000000  0.393795  ...  0.393795  0.393795  0.000000\n","3  0.000000  0.284319  0.000000  ...  0.000000  0.000000  0.352406\n","4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","\n","[5 rows x 26 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["we are using the sklearn TfidfVectorizer().\n","the syntax for this method looks like this\n","\n","class sklearn.feature_extraction.text.TfidfVectorizer(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.float64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n","\n","in the same way the countvectorizer has preprocessing tools the tfidf vectorizer does as well. \n","\n","this converts a collection of raw documents to a matrix of TF-IDF features and is equivalent to CountVectorizer followed by TfidfTransformer.\n","\n","Because this procedure is basically the same as the countvectorizer followed by a transformer we are also getting a sparse matrix which needs to be transformed in the same way as the bag of words from before.\n"],"metadata":{"id":"q8Z1R7izNslZ"}},{"cell_type":"markdown","source":["Now if we want to compare the sentences from our corporas and see their similarities there are some methods we can use.\n","we will start of with the euclidean distance."],"metadata":{"id":"IF6SgVyhOnJT"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import euclidean_distances\n","\n","eucl = euclidean_distances(bow)\n","eucl = pd.DataFrame(eucl, columns=[\"S1\",\"S2\",\"S3\",\"S4\",\"S5\"])\n","eucl.index = list([\"S1\",\"S2\",\"S3\",\"S4\",\"S5\"])\n","eucl_clean = eucl.loc[:, (eucl != 0).any(axis=0)]\n","eucl_clean = eucl_clean.loc[(eucl_clean !=0).any(axis=1)]\n","eucl_clean\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eSCcue8KQO_7","executionInfo":{"status":"ok","timestamp":1642158617859,"user_tz":-60,"elapsed":12,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"0148617b-e328-4002-b7a3-b25816a8fa83"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-01f66427-f152-4e05-a5cf-a721059f0d1b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S1</th>\n","      <th>S2</th>\n","      <th>S3</th>\n","      <th>S4</th>\n","      <th>S5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>S1</th>\n","      <td>0.000000</td>\n","      <td>3.605551</td>\n","      <td>3.605551</td>\n","      <td>3.741657</td>\n","      <td>3.464102</td>\n","    </tr>\n","    <tr>\n","      <th>S2</th>\n","      <td>3.605551</td>\n","      <td>0.000000</td>\n","      <td>3.464102</td>\n","      <td>3.605551</td>\n","      <td>3.316625</td>\n","    </tr>\n","    <tr>\n","      <th>S3</th>\n","      <td>3.605551</td>\n","      <td>3.464102</td>\n","      <td>0.000000</td>\n","      <td>3.872983</td>\n","      <td>3.605551</td>\n","    </tr>\n","    <tr>\n","      <th>S4</th>\n","      <td>3.741657</td>\n","      <td>3.605551</td>\n","      <td>3.872983</td>\n","      <td>0.000000</td>\n","      <td>3.464102</td>\n","    </tr>\n","    <tr>\n","      <th>S5</th>\n","      <td>3.464102</td>\n","      <td>3.316625</td>\n","      <td>3.605551</td>\n","      <td>3.464102</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01f66427-f152-4e05-a5cf-a721059f0d1b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-01f66427-f152-4e05-a5cf-a721059f0d1b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-01f66427-f152-4e05-a5cf-a721059f0d1b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          S1        S2        S3        S4        S5\n","S1  0.000000  3.605551  3.605551  3.741657  3.464102\n","S2  3.605551  0.000000  3.464102  3.605551  3.316625\n","S3  3.605551  3.464102  0.000000  3.872983  3.605551\n","S4  3.741657  3.605551  3.872983  0.000000  3.464102\n","S5  3.464102  3.316625  3.605551  3.464102  0.000000"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["a = bow.toarray()\n","a[0]\n","#b = np.array([[0,1,0,2,1],[2,0,1,0,1]])\n","\n","#csim_test = cosine_similarity(b)\n","#csim_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwEnVbDzSBeX","executionInfo":{"status":"ok","timestamp":1642159196964,"user_tz":-60,"elapsed":231,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"f1f684c1-8401-4d60-8322-c3de2604b0b1"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0,\n","       0, 0, 0, 0])"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["To do so we use the euclidean_distance method from the sklearn package.\n","\n","its syntax is as described below:\n","sklearn.metrics.pairwise.euclidean_distances(X, Y=None, *, Y_norm_squared=None, squared=False, X_norm_squared=None)\n","\n","This method computes the distance matrix between each pair from a vector array X and Y. It is also able to deal with sparse matrices, which means that we do not have to pass our bag of words in an array like fashion. \n","\n","The Calculation of the Euclidean distance follows this formula:\n","\n","$d(x_{i},x_{c}) = \\sqrt{\\sum_{j=1}^{n}(x_{ij}-x_{cj})^2}$\n","\n","For our Example this would mean that the measurement could look like this:\n","\n","$S_{1} = (0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,2,0,0,0,0,0,0,0,0)$\n","$S_{2} = (1,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)$\n","\n","$d(S_{1},S_{2}) = \\sqrt{(0-1)^2+(0-1)^2+(0-0)^2+(0-0)^2+(0-1)^2+(0-0)^2+(0-0)^2+(0-1)^2+(1-0)^2+(1-0)^2+(1-0)^2+(1-0)^2+(0-0)^2+(0-0)^2+(2-0)^2+(0-0)^2+(0-0)^2+(0-0)^2+(0-0)^2+(0-0)^2+(0-0)^2+(0-0)^2+(0-0)^2} = \\sqrt{13}$\n","$=3.605551$\n","\n","As you can see this seems very easy for small dimensions but gets a bit tricky for higher dimensionality. Additionaly Euclidean distance is said to be performing good for two and three dimensions but not for dimensions higher than that.\n","\n","A measurement that is said to be a better fit for higher dimensions is the cosine similarity."],"metadata":{"id":"O4h7dyYSlhFZ"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","csim = cosine_similarity(bow)\n","csim = pd.DataFrame(csim, columns=[\"S1\",\"S2\",\"S3\",\"S4\",\"S5\"])\n","csim.index = list([\"S1\",\"S2\",\"S3\",\"S4\",\"S5\"])\n","csim_clean = csim.loc[:, (csim != 0).any(axis=0)]\n","csim_clean = csim_clean.loc[(csim_clean !=0).any(axis=1)]\n","csim_clean\n","#np.fill_diagonal(csim_clean.values, np.nan)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"7GQc0soINsRn","executionInfo":{"status":"ok","timestamp":1642158617860,"user_tz":-60,"elapsed":12,"user":{"displayName":"Lukas Marx","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12089797695045899740"}},"outputId":"cabdf90c-bfd6-4fbb-9d23-0c86d2c16614"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-24941d23-9025-488d-bb71-9fd937b57a7d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S1</th>\n","      <th>S2</th>\n","      <th>S3</th>\n","      <th>S4</th>\n","      <th>S5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>S1</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.133631</td>\n","      <td>0.223607</td>\n","      <td>0.144338</td>\n","    </tr>\n","    <tr>\n","      <th>S2</th>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.141421</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>S3</th>\n","      <td>0.133631</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.119523</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>S4</th>\n","      <td>0.223607</td>\n","      <td>0.141421</td>\n","      <td>0.119523</td>\n","      <td>1.000000</td>\n","      <td>0.258199</td>\n","    </tr>\n","    <tr>\n","      <th>S5</th>\n","      <td>0.144338</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.258199</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24941d23-9025-488d-bb71-9fd937b57a7d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-24941d23-9025-488d-bb71-9fd937b57a7d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-24941d23-9025-488d-bb71-9fd937b57a7d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          S1        S2        S3        S4        S5\n","S1  1.000000  0.000000  0.133631  0.223607  0.144338\n","S2  0.000000  1.000000  0.000000  0.141421  0.000000\n","S3  0.133631  0.000000  1.000000  0.119523  0.000000\n","S4  0.223607  0.141421  0.119523  1.000000  0.258199\n","S5  0.144338  0.000000  0.000000  0.258199  1.000000"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["To calculate the cosine similarity we are also using the sklearn package but this time the cosine similarity method.\n","\n","its syntax is displayed here:\n","\n","sklearn.metrics.pairwise.cosine_similarity(X, Y=None, dense_output=True)\n","\n","This computes the cosine similarity between samples in X and Y.\n","The Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y. \n","\n","As like the euclidean distance it is able to deal with sparse matrices, which means that we do not have to pass our bag of words in an array like fashion.\n","\n","The calculation of this formula looks like this:\n","\n","$cosine(x_{i},x_{i'}) = \\frac{\\sum_{j=1}^{d}(x_{ij}*x_{i'j})}{\\sqrt{\\sum_{j=1}^{d}(x_{ij}^{2})}\\sqrt{\\sum_{j=1}^{d}(x_{i'j}^{2})}}$\n","\n","Calculating the cosine similarity for our example of S_1 and S_2 it would look like this:\n","\n","$cosine(S_{1},S_{2}) = \\frac{(0*1)+(0*1)+(0*0)+(0*0)+(0*1)+(0*0)+(0*0)+(0*1)+(1*0)+(1*0)+(1*0)+(1*0)+(0*0)+(0*0)+(2*0)+(0*0)+(0*0)+(0*0)+(0*0)+(0*0)+(0*0)+(0*0)+(0*0)}{\\sqrt{0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+1^2+1^2+1^2+1^2+0^2+0^2+2^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2}*\\sqrt{1^2+1^2+0^2+0^2+1^2+0^2+0^2+1^2+0^2+0^2+1^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2+0^2}}$\n","\n","$= \\frac{0}{\\sqrt{8}*\\sqrt{5}}$\n","$=0$\n","\n","This also seems very tricky for higher dimensions but is said to work better on higher dimensions than the euclidean distance. In my opinion the results of the cosine similarity are easier to understand."],"metadata":{"id":"iUvJ1_tLs5aO"}}]}